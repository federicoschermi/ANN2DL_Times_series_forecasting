{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":4266.105104,"end_time":"2022-01-13T15:04:00.868907","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-01-13T13:52:54.763803","version":"2.3.3"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7141631,"sourceType":"datasetVersion","datasetId":4122000},{"sourceId":7198999,"sourceType":"datasetVersion","datasetId":4163771}],"dockerImageVersionId":30581,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport pydot\nimport graphviz\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)\n\nfrom sklearn.preprocessing import MinMaxScaler, RobustScaler\nfrom sklearn.model_selection import StratifiedShuffleSplit","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:49:40.804660Z","iopub.execute_input":"2023-12-19T20:49:40.805024Z","iopub.status.idle":"2023-12-19T20:49:44.753051Z","shell.execute_reply.started":"2023-12-19T20:49:40.804991Z","shell.execute_reply":"2023-12-19T20:49:44.752103Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"2.13.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"papermill":{"duration":0.029663,"end_time":"2022-01-13T13:53:12.277831","exception":false,"start_time":"2022-01-13T13:53:12.248168","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-19T20:49:45.802307Z","iopub.execute_input":"2023-12-19T20:49:45.802906Z","iopub.status.idle":"2023-12-19T20:49:45.809354Z","shell.execute_reply.started":"2023-12-19T20:49:45.802873Z","shell.execute_reply":"2023-12-19T20:49:45.807404Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the data\nX = np.load('/kaggle/input/datidati/training_data.npy')\ncategories = np.load(\"/kaggle/input/datidati/categories.npy\")\nvalid_periods = np.load('/kaggle/input/datidati/valid_periods.npy')\nstart_times = valid_periods[:,0]\nend_times = valid_periods[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_categories(categories):\n    unique_categories = np.unique(categories)\n    category_to_int = {category: i for i, category in enumerate(unique_categories)}\n    return np.array([category_to_int[category] for category in categories])","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:49:55.270520Z","iopub.execute_input":"2023-12-19T20:49:55.271359Z","iopub.status.idle":"2023-12-19T20:49:55.276419Z","shell.execute_reply.started":"2023-12-19T20:49:55.271325Z","shell.execute_reply":"2023-12-19T20:49:55.275484Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''\n\nX = np.load('/kaggle/input/datidati/training_data.npy')\n\n# Create an empty list to store scaled rows\nX_scaled=X.copy()\n\n# Convert scales and centers lists to NumPy arrays\nscales = np.zeros(X.shape[0])\ncenters = np.zeros(X.shape[0])\n\nstrange_s=[]\nstrange_c=[]\n\n# Scale each row of X independently\nfor i in range(X.shape[0]):  # Loop over each row\n\n    # Create a mask for non-zero values in the current row\n    non_zero_mask = (X[i, :] != 0.0)\n\n    # Extract non-zero values for fitting the scaler\n    non_zero_data = X[i, non_zero_mask].reshape(-1, 1)\n\n    # Initialize the scaler and fit on non-zero data\n    scaler = RobustScaler().fit(non_zero_data)\n\n    # Save the scale and center for the current row\n    scales[i]=scaler.scale_[0]\n    centers[i]=scaler.center_[0]\n    \n    if (scales[i]>0.9 or scales[i]<0.05):\n        strange_s.append(i)\n        \n    if (centers[i]>0.9 or centers[i]<0.05):\n        strange_c.append(i)\n\n    # Transform the entire row using the fitted scaler\n    X_scaled_row = scaler.transform(X[i, non_zero_mask].reshape(-1, 1)).flatten()\n\n    # Fill the non-zero elements with the scaled values\n    X_scaled[i, non_zero_mask] = X_scaled_row\n\nprint(X_scaled.shape, scales.shape,centers.shape, len(strange_s), len(strange_c))\n\n'''","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:52:19.534700Z","iopub.execute_input":"2023-12-19T20:52:19.535075Z","iopub.status.idle":"2023-12-19T20:53:06.698501Z","shell.execute_reply.started":"2023-12-19T20:52:19.535044Z","shell.execute_reply":"2023-12-19T20:53:06.697211Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(48000, 2776) (48000,) (48000,) 365 361\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set a seed for reproducibility\nseed = 42  # You can use any integer as the seed\n\n# Define the StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=seed)\n\ntrain_indexes=[]\nval_indexes=[]\n\n# Perform the split\nfor train_index, val_index in sss.split(X, categories):\n    X_train_noseq, X_val_noseq = X[train_index], X[val_index]\n    cat_train_noseq, cat_val_noseq = categories[train_index], categories[val_index]\n    train_indexes.append(train_index)\n    val_indexes.append(val_index)\n\n# Check the shapes of the resulting sets\nprint(\"X_train shape:\", X_train_noseq.shape)\nprint(\"X_val shape:\", X_val_noseq.shape)\nprint(\"cat_train shape:\", cat_train_noseq.shape)\nprint(\"cat_val shape:\", cat_val_noseq.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:56:35.805262Z","iopub.execute_input":"2023-12-19T20:56:35.805933Z","iopub.status.idle":"2023-12-19T20:56:36.135163Z","shell.execute_reply.started":"2023-12-19T20:56:35.805901Z","shell.execute_reply":"2023-12-19T20:56:36.134198Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"X_train shape: (42692, 2776)\nX_val shape: (4744, 2776)\ncat_train shape: (42692,)\ncat_val shape: (4744,)\n","output_type":"stream"}]},{"cell_type":"code","source":"def extract_sequences(array, window, stride, start_times, end_times, categories, shuffle=True, seed=42, telescope=9):\n    X = []\n    y = []\n    cat=[]\n    \n    category_flags = encode_categories(categories)  # Integer-encode the category flags\n\n    for idx in range(len(array)):\n        start_time = start_times[idx]\n        end_time = end_times[idx]\n        category_flag = category_flags[idx]  # Extract the integer-encoded category flag\n\n        # Extract the actual non-zero part of the time series within the specified time range\n        actual_data = array[idx, start_time:end_time]\n\n        padding_check = len(actual_data)%window\n\n        if(padding_check != 0):\n            # Compute padding length\n            padding_len = window - len(actual_data)%window\n            padding = np.zeros(padding_len,dtype='float32')\n            actual_data = np.concatenate((padding,actual_data))\n            assert len(actual_data) % window == 0\n\n        # Genera sequenze con la finestra e lo stride specificati\n        for i in range(0, len(actual_data) - window - telescope, stride):\n            sequence = actual_data[i:i + window]\n            X.append(sequence)\n            y.append(actual_data[i+window: i+ window+telescope])\n            cat.append(categories[idx])\n\n\n    X = np.array(X)\n    y = np.array(y)\n    cat=np.array(cat)\n\n    if shuffle:\n        np.random.seed(seed)\n        indices = np.arange(len(X))\n        np.random.shuffle(indices)\n        X = X[indices]\n        y = y[indices]\n        cat = cat[indices]\n\n    cat=encode_categories(cat)\n        \n    return X, y, cat\n","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:56:37.706125Z","iopub.execute_input":"2023-12-19T20:56:37.706923Z","iopub.status.idle":"2023-12-19T20:56:37.721016Z","shell.execute_reply.started":"2023-12-19T20:56:37.706892Z","shell.execute_reply":"2023-12-19T20:56:37.719832Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\n# Set a seed for reproducibility\nseed = 42 \n\n# Define the StratifiedShuffleSplit\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=seed)\n\ntrain_indexes=[]\nval_indexes=[]\n\n# Perform the split\nfor train_index, val_index in sss.split(X, categories):\n    X_train_noseq, X_val_noseq = X[train_index], X[val_index]\n    cat_train_noseq, cat_val_noseq = categories[train_index], categories[val_index]\n    train_indexes.append(train_index)\n    val_indexes.append(val_index)\n\n# Check the shapes of the resulting sets\nprint(\"X_train_noseq shape:\", X_train_noseq.shape)\nprint(\"X_val_noseq shape:\", X_val_noseq.shape)\nprint(\"cat_train_noseq shape:\", cat_train_noseq.shape)\nprint(\"cat_val_noseq shape:\", cat_val_noseq.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:56:41.436190Z","iopub.execute_input":"2023-12-19T20:56:41.436549Z","iopub.status.idle":"2023-12-19T20:56:41.769074Z","shell.execute_reply.started":"2023-12-19T20:56:41.436522Z","shell.execute_reply":"2023-12-19T20:56:41.768096Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"X_train_noseq shape: (42692, 2776)\nX_val_noseq shape: (4744, 2776)\ncat_train_noseq shape: (42692,)\ncat_val_noseq shape: (4744,)\n","output_type":"stream"}]},{"cell_type":"code","source":"sequence_length = 100\nstride = 12\n\n#X_train, y_train = build_sequences(X, start_times, end_times, telescope=telescope_size, window=window_size, stride=stride_size)\ncategories = np.load(\"/kaggle/input/datidati/categories.npy\")\n\nstart_times_train=start_times[train_indexes][0]\nend_times_train=end_times[train_indexes][0]\n\nstart_times_val=start_times[val_indexes][0]\nend_times_val=end_times[val_indexes][0]\n\nX_train, y_train, cat_train = extract_sequences(X_train_noseq,sequence_length,stride, start_times_train, end_times_train, cat_train_noseq)\nX_val, y_val, cat_val = extract_sequences(X_val_noseq,sequence_length,stride, start_times_val, end_times_val, cat_val_noseq)","metadata":{"papermill":{"duration":1.713224,"end_time":"2022-01-13T13:53:18.13758","exception":false,"start_time":"2022-01-13T13:53:16.424356","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-12-19T20:56:45.330132Z","iopub.execute_input":"2023-12-19T20:56:45.330493Z","iopub.status.idle":"2023-12-19T20:56:47.702305Z","shell.execute_reply.started":"2023-12-19T20:56:45.330466Z","shell.execute_reply":"2023-12-19T20:56:47.701289Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"X_train.shape, y_train.shape, cat_train.shape, X_val.shape, y_val.shape, cat_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:56:48.720926Z","iopub.execute_input":"2023-12-19T20:56:48.721280Z","iopub.status.idle":"2023-12-19T20:56:48.728508Z","shell.execute_reply.started":"2023-12-19T20:56:48.721253Z","shell.execute_reply":"2023-12-19T20:56:48.727606Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"((490855, 100), (490855, 9), (490855,), (53770, 100), (53770, 9), (53770,))"},"metadata":{}}]},{"cell_type":"code","source":"\nclass TimeSeriesAugmentation(tf.keras.layers.Layer):\n    def __init__(self, jitter=0.01, scale=0.1, time_warping=0.2, magnitude_warping=0.2, **kwargs):\n        super(TimeSeriesAugmentation, self).__init__(**kwargs)\n        self.jitter = jitter\n        self.scale = scale\n        self.time_warping = time_warping\n        self.magnitude_warping = magnitude_warping\n\n    def call(self, inputs, training=None):\n        if training:\n            augmented_inputs = self.augment(inputs)\n            return augmented_inputs\n        return inputs\n\n    def augment(self, series):\n        # Apply jitter\n        noise = np.random.normal(0, self.jitter, size=len(series))\n        series = series + noise\n\n        # Apply scaling\n        scaling_factor = np.random.uniform(1 - self.scale, 1 + self.scale)\n        series = series * scaling_factor\n\n        # Apply time warping\n        num_points = len(series)\n        time_warp_factor = np.random.uniform(1 - self.time_warping, 1 + self.time_warping)\n        warped_indices = np.arange(0, num_points, time_warp_factor)[:num_points]\n        series = np.interp(np.arange(num_points), warped_indices, series)\n\n        # Apply magnitude warping\n        magnitude_warp_factor = np.random.uniform(1 - self.magnitude_warping, 1 + self.magnitude_warping)\n        series = series * magnitude_warp_factor\n\n        return series\n    \n    \n    \ndef create_input_mask(inputs):\n    # Create a mask for positions with zero values in the inputs\n    mask = tf.cast(tf.math.not_equal(inputs, 0.0), tf.float32)\n    return np.array(mask)\n\n\ninput_mask = create_input_mask(X_train)\nprint(input_mask.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-19T20:56:57.855106Z","iopub.execute_input":"2023-12-19T20:56:57.855859Z","iopub.status.idle":"2023-12-19T20:56:57.865302Z","shell.execute_reply.started":"2023-12-19T20:56:57.855828Z","shell.execute_reply":"2023-12-19T20:56:57.864324Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Define a custom layer for applying weights to the dot product\nclass WeightedDotProduct(layers.Layer):\n    def __init__(self, **kwargs):\n        super(WeightedDotProduct, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        # Create a trainable weight variable for this layer\n        self.kernel = self.add_weight(name='kernel',\n                                      shape=(input_shape[2], 1),\n                                      initializer='uniform',\n                                      trainable=True)\n        super(WeightedDotProduct, self).build(input_shape)  # Be sure to call this at the end\n\n    def call(self, x):\n        return tf.matmul(x, self.kernel)\n\n    \n    \ndef scaled_dot_product_attention(q, k, v, mask=None, dropout=None):\n    \"\"\"\n    Computes scaled dot-product attention.\n\n    Args:\n        q (tensor): Query tensor of shape (..., seq_len_q, depth_k).\n        k (tensor): Key tensor of shape (..., seq_len_k, depth_k).\n        v (tensor): Value tensor of shape (..., seq_len_v, depth_v).\n        mask (tensor, optional): Optional mask for the attention weights.\n                                 Shape broadcastable to (..., seq_len_q, seq_len_k).\n        dropout (function, optional): Optional dropout function to be applied to attention weights.\n\n    Returns:\n        tuple: A tuple containing the attention output and the attention weights.\n               Output shape is (..., seq_len_q, depth_v) and attention weights shape is (..., seq_len_q, seq_len_k).\n    \"\"\"\n    # Compute the dot product of Q and K, transposing the last two dimensions of K\n    matmul_qk = tf.matmul(q, k, transpose_b=True)  # shape: (..., seq_len_q, seq_len_k)\n\n    # Scale the dot product by the square root of the depth of K\n    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n\n    # Apply the mask if provided\n    if mask is not None:\n        scaled_attention_logits += (mask * -1e9)\n\n    # Apply softmax to compute attention weights\n    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n\n    # Apply dropout to the attention weights if provided\n    if dropout is not None:\n        attention_weights = dropout(attention_weights)\n\n    # Multiply attention weights with V to get the output\n    output = tf.matmul(attention_weights, v)\n\n    return output, attention_weights\n    \nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Define the MultiHeadAttention layer\nheads = 4  # Choose the number of heads\nd_model = 128  # Choose the model dimension\n\nmulti_head_attention = tf.keras.layers.MultiHeadAttention(num_heads=heads, key_dim=d_model//heads)\n\n\ndef build_lstm_seq2seq_multihead_attention(input_shape, n_units, N_values_to_predict):\n    \n    input_layer = tf.keras.Input(shape=input_shape, name='Input')\n\n    encoder_x, encoder_h, encoder_c = tf.keras.layers.LSTM(units=n_units, return_sequences=True, return_state=True)(input_layer)\n\n    decoder_in = tf.keras.layers.RepeatVector(1)(encoder_h)\n\n    x = tf.keras.layers.LSTM(units=n_units, return_sequences=True, return_state=False)(decoder_in, initial_state=[encoder_h, encoder_c])\n\n    decoder_x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=int(n_units/2), return_sequences=True, return_state=False))(x)\n\n    #print(decoder_x.shape)\n    #print(decoder_in.shape)\n    \n    #print(encoder_x.shape)\n    #print(encoder_c.shape)\n    #print(encoder_h.shape)\n\n    # Create query, key, and value inputs\n    query = decoder_x\n    key = attention\n    value = encoder_h  # You can modify this based on your requirements\n\n    # Apply MultiHeadAttention with explicit query, key, value inputs\n    attention_output = multi_head_attention(query, key, value, return_attention_scores=True)\n\n    # Get the attention output and attention weights\n    output = attention_output[0]\n    attention_weights = attention_output[1]\n\n    # Apply the weighted dot product using the attention weights\n    weighted_dot_product = tf.keras.layers.Dot(axes=[2, 2])([attention_weights, value])\n\n    context = tf.keras.layers.Dot(axes=[2, 1])([weighted_dot_product, encoder_x])\n\n    concatenated_c = tfkl.Concatenate()([context, decoder_x])\n    concatenated_c = tfkl.Flatten()(concatenated_c)\n    \n    output_layer = tfkl.Dense(N_values_to_predict)(concatenated_c)  # number of telescope values\n\n    model = tfk.Model(inputs=[input_layer, category_input], outputs=output_layer, name='model')\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## input_shape = (None, 1)\n\nepochs = 20\n\nbatch_size = 128\n\nlstm_units = 64\n\nN_values_to_predict=9\n\n#with tpu_strategy.scope():\n    \nmodel = build_lstm_seq2seq_multihead_attention(input_shape,lstm_units,9)\n    \nmodel.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(1e-3), metrics=['mae'], steps_per_execution=32)\n\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with tpu_strategy.scope():\n\nhistory = model.fit(\n    \n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs = epochs,\n    batch_size = batch_size,\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.5, min_lr=1e-5)\n    ]\n).history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nmodel.save('SubmissionModel_convnuovo')\nshutil.make_archive('SubmissionModel_convnuovo', 'zip', 'SubmissionModel_convnuovo')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef residual_block(x, filters, kernel_size=3, activation='relu', padding='same'):\n    # Shortcut\n    shortcut = x\n\n    # First convolution\n    x = Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(x)\n\n    # Second convolution\n    x = Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(x)\n\n    # Adjust dimensions of the shortcut\n    shortcut = Conv1D(filters=filters, kernel_size=1, activation=None, padding='same')(shortcut)\n\n    # Add shortcut to the output\n    x = tfkl.Add()([x, shortcut])\n\n    return x\n\n\ndef build_conv1d_lstm_resnet(input_shape, n_units, N_values_to_predict=9, filters=64,kernel_size=3):\n\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    # Apply 1D Convolutional layer with residual block\n    conv1d_layer = residual_block(input_layer, filters=filters, kernel_size=kernel_size, activation='relu', padding='same')\n    maxpooling_layer = MaxPooling1D(pool_size=2)(conv1d_layer)\n\n    # Apply 1D Convolutional layer with residual block\n    conv1d_layer = residual_block(maxpooling_layer, filters=128, kernel_size=3, activation='relu', padding='same')\n    maxpooling_layer = MaxPooling1D(pool_size=2)(conv1d_layer)\n\n    # LSTM Encoder\n    encoder_x, encoder_h, encoder_c = tfkl.LSTM(units=n_units, return_sequences=True, return_state=True)(maxpooling_layer)\n\n    decoder_in = tfkl.RepeatVector(1)(encoder_h)\n\n    x = tfkl.LSTM(units=n_units, return_sequences=True,return_state=False)(decoder_in,initial_state=[encoder_h,encoder_c])\n    decoder_x = tfkl.Bidirectional(tfkl.LSTM(units=int(n_units/2), return_sequences=True,return_state=False))(x)\n\n    attention = tfkl.Dot(axes=[2,2])([decoder_x, encoder_x])\n    attention = tfkl.Activation('softmax')(attention)\n    context = tfkl.Dot(axes=[2,1])([attention,encoder_x])\n\n    \n    concatenated_c = tfkl.Concatenate()([context,decoder_x])\n    concatenated_c = tfkl.Flatten()(concatenated_c)\n\n    concatenated_c = Dropout(0.5)(concatenated_c)  # Add dropout for regularization\n\n    output_layer = tfkl.Dense(N_values_to_predict, activation='linear')(concatenated_c) #number of my telescope values!!!!!\n\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='build_conv1d_lstm_resnet')\n\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (None, 1)\n\nepochs = 20\n\nbatch_size = 128\n\nlstm_units = 64\n\nN_values_to_predict=9\n\n#with tpu_strategy.scope():\n    \nmodel = build_conv1d_lstm_resnet(input_shape,lstm_units)\n    \nmodel.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(1e-3), metrics=['mae'], steps_per_execution=32)\n\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory = model.fit(\n    \n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs = epochs,\n    batch_size = batch_size,\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.5, min_lr=1e-5)\n    ]\n).history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nmodel.save('conv_lstm_resnet_attention')\nshutil.make_archive('conv_lstm_resnet_attention', 'zip', 'conv_lstm_resnet_attention')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Attempt to create a resnet-like block with multihead attention ","metadata":{}},{"cell_type":"code","source":"\ndef multihead_attention(query, key, value, heads, d_model):\n    \"\"\"\n    MultiHeadAttention layer\n    \"\"\"\n    concat = tf.keras.layers.Concatenate(axis=-1)\n    dense = tf.keras.layers.Dense(units=d_model, activation='linear')\n\n    # Split the query, key, and value into multiple heads\n    query = tf.keras.layers.Lambda(lambda x: tf.split(x, heads, axis=-1))(query)\n    key = tf.keras.layers.Lambda(lambda x: tf.split(x, heads, axis=-1))(key)\n    value = tf.keras.layers.Lambda(lambda x: tf.split(x, heads, axis=-1))(value)\n\n    # Apply attention to each head\n    attention_heads = []\n    for i in range(heads):\n        attention_heads.append(tf.keras.layers.Attention()([query[i], key[i], value[i]]))\n\n    # Concatenate the attention heads\n    attention = concat(attention_heads)\n\n    # Final linear layer\n    output = dense(attention)\n\n    return output\n\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Dense, Flatten, RepeatVector, Bidirectional, LSTM, Add, Dot, Activation, Concatenate\nfrom tensorflow.keras.models import Model\n\n\n\ndef residual_block_with_attention(x, filters, kernel_size=3, activation='relu', padding='same', heads=4, d_model=64):\n    # Shortcut\n    shortcut = x\n\n    # First convolution\n    x = Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(x)\n\n    # Second convolution\n    x = Conv1D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(x)\n\n    # Adjust dimensions of the shortcut\n    shortcut = Conv1D(filters=filters, kernel_size=1, activation=None, padding='same')(shortcut)\n\n    # Add multihead attention to the output\n    x = multihead_attention(x, x, x, heads, d_model)\n\n    # Apply a linear transformation to the shortcut to match the dimensions\n    shortcut = Conv1D(filters=d_model, kernel_size=1, activation=None, padding='same')(shortcut)\n\n    # Add shortcut to the output\n    x = Add()([x, shortcut])\n\n    return x\n\n\ndef build_conv1d_lstm_resnet_with_attention(input_shape, n_units, N_values_to_predict=9, filters=64, kernel_size=3, heads=4, d_model=64):\n    input_layer = tf.keras.layers.Input(shape=input_shape, name='Input')\n\n    # Apply 1D Convolutional layer with residual block and attention\n    conv1d_layer = residual_block_with_attention(input_layer, filters=filters, kernel_size=kernel_size, activation='relu', padding='same', heads=heads, d_model=d_model)\n    maxpooling_layer = MaxPooling1D(pool_size=2)(conv1d_layer)\n\n    # Apply 1D Convolutional layer with residual block and attention\n    conv1d_layer = residual_block_with_attention(maxpooling_layer, filters=128, kernel_size=3, activation='relu', padding='same', heads=heads, d_model=d_model)\n    maxpooling_layer = MaxPooling1D(pool_size=2)(conv1d_layer)\n\n    # LSTM Encoder\n    encoder_x, encoder_h, encoder_c = LSTM(units=n_units, return_sequences=True, return_state=True)(maxpooling_layer)\n\n    decoder_in = RepeatVector(1)(encoder_h)\n\n    x = LSTM(units=n_units, return_sequences=True, return_state=False)(decoder_in, initial_state=[encoder_h, encoder_c])\n    decoder_x = Bidirectional(LSTM(units=int(n_units/2), return_sequences=True, return_state=False))(x)\n\n    attention = Dot(axes=[2, 2])([decoder_x, encoder_x])\n    attention = Activation('softmax')(attention)\n    context = Dot(axes=[2, 1])([attention, encoder_x])\n\n    concatenated_c = Concatenate()([context, decoder_x])\n    concatenated_c = Flatten()(concatenated_c)\n\n    concatenated_c = Dropout(0.5)(concatenated_c)  # Add dropout for regularization\n\n    output_layer = Dense(N_values_to_predict, activation='linear')(concatenated_c)\n\n    model = Model(inputs=input_layer, outputs=output_layer, name='build_conv1d_lstm_resnet_with_attention')\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = (None, 1)\n\nepochs = 100\n\nbatch_size = 128\n\nlstm_units = 64\n\nN_values_to_predict=9\n\n#with tpu_strategy.scope():\n    \nmodel = build_conv1d_lstm_resnet_with_attention(input_shape,lstm_units)\n    \nmodel.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(1e-3), metrics=['mae'], steps_per_execution=32)\n\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with tpu_strategy.scope():\n\nhistory = model.fit(\n    \n    X_train, y_train,\n    validation_data=(X_val, y_val),\n   # {'Input': X_train, 'Category_Input': cat_train}, y_train, # Provide input data as a dictionary\n\n    #validation_data=({'Input': X_val, 'Category_Input': cat_val}, y_val), # Provide input data as a dictionary\n\n    epochs = epochs,\n    batch_size = batch_size,\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=10, factor=0.5, min_lr=1e-5)\n    ]\n).history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nmodel.save('SubmissionModel_resnet_attention')\nshutil.make_archive('SubmissionModel_resnet_attention', 'zip', 'SubmissionModel_resnet_attention')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## General comments on the resnet-like architecture\nThe performance seemed good in validation but there is clearly some mistake on the implementation. As we do not understand the error and we prefer not to act blindly, we leave it like this and move to more understandable models.","metadata":{}},{"cell_type":"code","source":"'''\nfrom sklearn.preprocessing import RobustScaler\n\nclass model:\n    def __init__(self, path):\n        self.model = tf.keras.models.load_model(os.path.join(path, 'SubmissionModel'))\n\n    def predict(self, X, categories):\n\n        unique_categories = np.unique(categories)\n        category_to_int = {category: i for i, category in enumerate(unique_categories)}\n        final_categories = np.array([category_to_int[category] for category in categories])\n\n        categories=final_categories\n       \n        input_data = {'Input': X, 'Category_Input': categories}\n        \n        out = self.model.predict(input_data)\n\n        return out\n    \n\n# Assuming you have your original data X\nX_pred = X[val_indexes[0][1:10],:]  # Your original data\nc = categories[val_indexes[0][1:10]]  # Your original data\n# Initialize the scaler\nscaler = RobustScaler()\n\n# Lists to store scaling parameters for each row\ncentering_params_list = []\nscaling_params_list = []\nX_scaled_list = []\n\n# Scale each row of X independently\nfor i in range(X_pred.shape[0]):\n    row = X_pred[i, :].reshape(-1, 1)  # Reshape to 2D array (column vector)\n\n    # Create a mask for non-zero values\n    non_zero_mask = row != 0\n\n    # Apply RobustScaler only to non-zero values\n    scaled_non_zero_data = scaler.fit_transform(row[non_zero_mask].reshape(-1, 1))\n    \n    # Create a new array with the same shape as the original row\n    scaled_row = np.zeros_like(row, dtype=np.float64)\n    scaled_row[non_zero_mask] = scaled_non_zero_data.flatten()\n\n    # Save the scaling parameters for the current row\n    centering_params_list.append(scaler.center_)\n    scaling_params_list.append(scaler.scale_)\n\n    # Store the scaled row\n    X_scaled_list.append(scaled_row.flatten())\n\n    \n# Stack the scaled rows into a 2D array\nX_scaled = np.vstack(X_scaled_list)\n\nprint(X_scaled.shape)\n\n# Assuming you have X_test and cat_test for test data\nmy_model = model('/kaggle/working/')\n\n# Assuming you have X_test and cat_test for test data\npredictions = my_model.predict(X_scaled, cat_pred)\n\n# Assuming you want to invert the scaling for the predictions\npredictions_original_scale = np.zeros_like(predictions, dtype=np.float64)\n\n# Lists to store inverted scaling for each row\nfor i in range(predictions.shape[0]):\n    scaled_row = predictions[i, :].reshape(-1, 1)  # Reshape to 2D array (column vector)\n\n    # Use the saved scaling parameters for the current row\n    centering_params = centering_params_list[i]\n    scaling_params = scaling_params_list[i]\n\n    # Inverse transform for the current row\n    row_original_scale = scaled_row * scaling_params + centering_params\n\n    # Store the inverted scaled row\n    predictions_original_scale[i, :] = row_original_scale.flatten()\n\n\nplt.figure()\nfor i in range (X_scaled.shape[0]):\n    plt.plot(predictions_original_scale[:,i])\n\npredictions_original_scale.shape\n\n\n# Perform your operations on the scaled data (if needed)\n\n# Lists to store inverted scaling for each row\nX_original_list = []\n\n#HERE I WILL HAVE MU PREDICTIONS Y\n\n# Invert the scaling for each row separately\nfor i in range(X_scaled.shape[0]):\n    scaled_row = X_scaled[i, :].reshape(-1, 1)  # Reshape to 2D array (column vector)\n\n    # Use the saved scaling parameters for the current row\n    centering_params = centering_params_list[i]\n    scaling_params = scaling_params_list[i]\n\n    # Inverse transform for the current row\n    X_original_non_zero_data = scaler.inverse_transform(scaled_row[non_zero_mask].reshape(-1, 1))\n    \n    # Create a new array with the same shape as the original row\n    X_original_row = np.zeros_like(scaled_row, dtype=np.float64)\n    X_original_row[non_zero_mask] = X_original_non_zero_data.flatten()\n\n    # Store the inverted scaled row\n    X_original_list.append(X_original_row.flatten())\n\n# Stack the inverted scaled rows into a 2D array\nX_original = np.vstack(X_original_list)\n\n# Check if the two approaches result in the same data\nprint(np.allclose(X, X_original))\n\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}