{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4266.105104,
      "end_time": "2022-01-13T15:04:00.868907",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-01-13T13:52:54.763803",
      "version": "2.3.3"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7141631,
          "sourceType": "datasetVersion",
          "datasetId": 4122000
        }
      ],
      "dockerImageVersionId": 30627,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.14\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "#import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)\n",
        "\n",
        "# Random seed for reproducibility\n",
        "seed = 42\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)\n",
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Bidirectional, Embedding, RepeatVector, Dense, Dot, Activation, Concatenate, Flatten,Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D, BatchNormalization, Dropout, Bidirectional,  MultiHeadAttention, LayerNormalization\n",
        "\n",
        "from statsmodels.tsa.stattools import pacf, acf\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:01:21.160623Z",
          "iopub.execute_input": "2023-12-20T19:01:21.161601Z",
          "iopub.status.idle": "2023-12-20T19:01:21.170369Z",
          "shell.execute_reply.started": "2023-12-20T19:01:21.161563Z",
          "shell.execute_reply": "2023-12-20T19:01:21.169295Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BjQv1hM7Z16",
        "outputId": "5e61f69e-d50a-4987-d2b5-05e517ff3a9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In this notebook, we try several models and combination of models with attention including CONV1D_LSTM . We try several architectures and combinations of data augmentation, masking"
      ],
      "metadata": {
        "id": "MCphOygKtvNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_padding(series, valid_period):\n",
        "    start, end = valid_period\n",
        "    return series[start:end]\n",
        "\n",
        "def encode_categories(categories):\n",
        "    # Integer encoding of categorical data (letters)\n",
        "    unique_categories = np.unique(categories)\n",
        "    category_to_int = {category: i for i, category in enumerate(unique_categories)}\n",
        "    return np.array([category_to_int[category] for category in categories])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:01:25.012155Z",
          "iopub.execute_input": "2023-12-20T19:01:25.012949Z",
          "iopub.status.idle": "2023-12-20T19:01:25.018820Z",
          "shell.execute_reply.started": "2023-12-20T19:01:25.012913Z",
          "shell.execute_reply": "2023-12-20T19:01:25.017917Z"
        },
        "trusted": true,
        "id": "YNi1smmt7Z18"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.load('/content/drive/MyDrive/Colab_Notebooks/AN2DL/Challenge_2/training_data.npy')\n",
        "valid_periods = np.load('/content/drive/MyDrive/Colab_Notebooks/AN2DL/Challenge_2/valid_periods.npy')\n",
        "categories = np.load('/content/drive/MyDrive/Colab_Notebooks/AN2DL/Challenge_2/categories.npy')\n",
        "categories=encode_categories(categories)\n",
        "\n",
        "start_times=valid_periods[:,0]\n",
        "end_times=valid_periods[:,1]\n",
        "\n",
        "trimmed_data = [remove_padding(X[i], valid_periods[i]) for i in range(len(X))]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:02:16.782191Z",
          "iopub.execute_input": "2023-12-20T19:02:16.782485Z",
          "iopub.status.idle": "2023-12-20T19:02:17.375093Z",
          "shell.execute_reply.started": "2023-12-20T19:02:16.782459Z",
          "shell.execute_reply": "2023-12-20T19:02:17.374084Z"
        },
        "trusted": true,
        "id": "ISB41VwE7Z19"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Here, we identify the anomalous interquartile range (above the threshold of 0.95 and below the threshold of 0.05) and remove this indexes, considering them as outliers"
      ],
      "metadata": {
        "id": "v65Avp3ytzVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Thresholds for identifying low and high scales\n",
        "low_threshold = 0.05\n",
        "high_threshold = 0.95\n",
        "\n",
        "# Initialize lists to store low and high scale information\n",
        "low_centers = []\n",
        "high_centers = []\n",
        "\n",
        "low_scales = []\n",
        "high_scales = []\n",
        "\n",
        "# Row-wise Robust Scaling\n",
        "Xpredscaled=np.zeros_like(X)\n",
        "scalespred = np.zeros(X.shape[0], dtype=float)\n",
        "centerspred = np.zeros(X.shape[0], dtype=float)\n",
        "\n",
        "for i in range(X.shape[0]):\n",
        "\n",
        "    # Extract each row as a column vector\n",
        "    row_data = X[i, :].reshape(-1, 1)\n",
        "\n",
        "    nonzero_mask = X[i, :] != 0\n",
        "\n",
        "    # Extract non-zero values and reshape to a column vector\n",
        "    row_data_nonzero = X[i, nonzero_mask].reshape(-1, 1)\n",
        "\n",
        "    # Fit the scaler to the non-zero values\n",
        "    scaler = RobustScaler().fit(row_data_nonzero)\n",
        "\n",
        "    # Apply scaling and flatten the result to the corresponding indices\n",
        "    Xpredscaled[i, nonzero_mask] = scaler.transform(row_data_nonzero).flatten()\n",
        "\n",
        "    # Store scale and center for later use\n",
        "    scalespred[i] = scaler.scale_[0]\n",
        "    centerspred[i] = scaler.center_[0]\n",
        "\n",
        "    # Categorize scales and store corresponding information\n",
        "    if scalespred[i] < low_threshold:\n",
        "        low_scales.append(i)\n",
        "\n",
        "    if scalespred[i] > high_threshold:\n",
        "        high_scales.append(i)\n",
        "\n",
        "    if centerspred[i] > high_threshold:\n",
        "        high_centers.append(i)\n",
        "\n",
        "    if centerspred[i] < low_threshold:\n",
        "        low_centers.append(i)\n",
        "\n",
        "# Convert lists to numpy arrays if needed\n",
        "low_scales = np.array(low_scales)\n",
        "high_scales = np.array(high_scales)\n",
        "\n",
        "# Convert lists to numpy arrays if needed\n",
        "low_centers = np.array(low_centers)\n",
        "high_centers = np.array(high_centers)\n",
        "\n",
        "# Union of scales\n",
        "all_scales = np.union1d(low_scales, high_scales)\n",
        "\n",
        "# Union of centers\n",
        "all_centers = np.union1d(low_centers, high_centers)\n",
        "\n",
        "all_indexes = np.union1d(all_scales, all_centers)\n",
        "\n",
        "len(all_indexes)\n",
        "\n",
        "\n",
        "print(len(all_scales), len(all_centers), len(all_indexes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPqbrrJpzCLd",
        "outputId": "597a1a15-e852-4ced-ea6e-c8cfbf6dc017"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "361 319 524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We plot the results\n",
        "\n",
        "N_rows=29\n",
        "N_cols=8\n",
        "\n",
        "\n",
        "for i in range (0, N_rows):\n",
        "    fig, axes = plt.subplots(1,N_cols, figsize=(20,2))\n",
        "    for j in range(N_cols):\n",
        "        index=i*N_rows+j\n",
        "        axes[j].plot(X[all_scales[index], start_times[all_scales[index]]: end_times[all_scales[index]]])\n",
        "        axes[j].set_title(f'i is {all_scales[index]} {categories[all_scales[index]]}')\n",
        "        axes[j].set_xlabel('Time')\n",
        "        axes[j].set_ylabel('Value')"
      ],
      "metadata": {
        "id": "eZKc_jx40GQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#First, we remove these outliers\n",
        "\n",
        "X_noout = np.delete(X, all_scales, axis=0)\n",
        "valid_periods_noout = np.delete(valid_periods, all_scales, axis=0)\n",
        "categories_noout = np.delete(categories, all_scales, axis=0)\n",
        "start_times_noout=valid_periods_noout[:,0]\n",
        "end_times_noout=valid_periods_noout[:,1]\n",
        "\n",
        "trimmed_data_noout = [row for i, row in enumerate(trimmed_data) if i not in all_scales]\n",
        "print(len(trimmed_data_noout))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2VkDkXj6SKd",
        "outputId": "ed4b2cd8-7a68-4f3b-fabe-9f876d8d4ccc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Find data too  SHORT, to exclude\n",
        "lengths = [len(series) for series in trimmed_data_noout]\n",
        "\n",
        "indexes_too_short=np.where(np.array(lengths)<=72)[0]\n",
        "print(indexes_too_short)\n",
        "\n",
        "indexes_too_long=np.where(np.array(lengths)>=1100)[0]\n",
        "print(indexes_too_long)\n",
        "\n",
        "indexes = np.insert(indexes_too_long,0,indexes_too_short)\n",
        "indexes=indexes_too_short\n",
        "print(len(indexes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHBD5bmP5vJI",
        "outputId": "f19422ec-014f-4c49-c532-c920f5da85f7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    3   105   108 ... 47500 47542 47620]\n",
            "[  121   210  2566  2569  2571 16979 17021 17026 17031 17032 17033 26593\n",
            " 27828 32755 35386 35888 35891 35899 35932 35934 36852 37091 43590]\n",
            "12763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_noout2 = np.delete(X_noout, indexes, axis=0)\n",
        "valid_periods_noout2 = np.delete(valid_periods_noout, indexes, axis=0)\n",
        "categories_noout2 = np.delete(categories_noout, indexes, axis=0)\n",
        "start_times_noout2=valid_periods_noout2[:,0]\n",
        "end_times_noout2=valid_periods_noout2[:,1]\n",
        "\n",
        "trimmed_data_noout2 = [row for i, row in enumerate(trimmed_data_noout) if i not in indexes]\n",
        "\n",
        "print(X_noout.shape, len(categories_noout),len(start_times_noout),len(end_times_noout) )\n",
        "print(len(trimmed_data_noout))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q8vpiCi61qD",
        "outputId": "04732460-60aa-4a97-b298-d674fe10f7aa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47639, 2776) 47639 47639 47639\n",
            "47639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_noout2.shape,valid_periods_noout2.shape, categories_noout2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcHRDWha6rBh",
        "outputId": "8ebfb380-b9b0-479f-c729-cff8456049e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34876, 2776) (34876, 2) (34876,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_sequences(array, window, stride, start_times, end_times, categories, shuffle=True, seed=42, telescope=18):\n",
        "    df = []\n",
        "    y = []\n",
        "    cat=[]\n",
        "\n",
        "    category_flags = encode_categories(categories)  # Integer-encode the category flags\n",
        "\n",
        "    for idx in range(len(array)):\n",
        "        start_time = start_times[idx]\n",
        "        end_time = end_times[idx]\n",
        "        category_flag = category_flags[idx]  # Extract the integer-encoded category flag\n",
        "\n",
        "        # Extract the actual non-zero part of the time series within the specified time range\n",
        "        actual_data = array[idx, start_time:end_time]\n",
        "\n",
        "        padding_check = len(actual_data)%window\n",
        "\n",
        "        if(padding_check != 0):\n",
        "            # Compute padding length\n",
        "            padding_len = window - len(actual_data)%window\n",
        "            padding = np.zeros(padding_len,dtype='float32')\n",
        "            actual_data = np.concatenate((padding,actual_data))\n",
        "            assert len(actual_data) % window == 0\n",
        "\n",
        "        # Genera sequenze con la finestra e lo stride specificati\n",
        "        for i in range(0, len(actual_data) - window - telescope, stride):\n",
        "\n",
        "            sequence = actual_data[i:i + window]\n",
        "\n",
        "            df.append(sequence)\n",
        "\n",
        "            y.append(actual_data[i+window: i+ window+telescope])\n",
        "            cat.append(categories[idx])\n",
        "\n",
        "    df = np.array(df)\n",
        "    y = np.array(y)\n",
        "    cat=np.array(cat)\n",
        "    cat=encode_categories(cat)\n",
        "\n",
        "    return df, y, cat"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:02:17.376668Z",
          "iopub.execute_input": "2023-12-20T19:02:17.377254Z",
          "iopub.status.idle": "2023-12-20T19:02:17.394304Z",
          "shell.execute_reply.started": "2023-12-20T19:02:17.377214Z",
          "shell.execute_reply": "2023-12-20T19:02:17.393423Z"
        },
        "trusted": true,
        "id": "Ns9Fqf4L7Z19"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "seed = 42\n",
        "\n",
        "myX=X_noout2\n",
        "mycategories=categories_noout2\n",
        "my_start_times=start_times_noout2\n",
        "my_end_times=end_times_noout2\n",
        "\n",
        "# Define the StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=seed)\n",
        "\n",
        "train_indexes=[]\n",
        "val_indexes=[]\n",
        "\n",
        "#We only use the categories in the stratified split\n",
        "\n",
        "# Perform the split\n",
        "for train_index, val_index in sss.split(myX, mycategories):\n",
        "  #even if we do not consider the categories relevant for the model, it does not hurt to respect the proportion of data (after oultier removal)\n",
        "\n",
        "    train_indexes.append(train_index)\n",
        "    val_indexes.append(val_index)\n",
        "\n",
        "    X_train_noseq, X_val_noseq = myX[train_index], myX[val_index]\n",
        "    cat_train_noseq, cat_val_noseq = mycategories[train_index], mycategories[val_index]\n",
        "    start_times_train_noseq, start_times_val_noseq = my_start_times[train_index], my_start_times[val_index]\n",
        "    end_times_train_noseq, end_times_val_noseq = my_end_times[train_index], my_end_times[val_index]\n",
        "\n",
        "\n",
        "# Check the shapes of the resulting sets\n",
        "print(\"X_train_noseq shape:\", X_train_noseq.shape)\n",
        "print(\"X_val_noseq shape:\", X_val_noseq.shape)\n",
        "print(\"cat_train_noseq shape:\", cat_train_noseq.shape)\n",
        "print(\"cat_val_noseq shape:\", cat_val_noseq.shape)\n",
        "print(\"start_times_train_noseq shape:\", start_times_train_noseq.shape)\n",
        "print(\"end_times_train_noseq shape:\", end_times_train_noseq.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:02:38.484459Z",
          "iopub.execute_input": "2023-12-20T19:02:38.485212Z",
          "iopub.status.idle": "2023-12-20T19:02:38.908117Z",
          "shell.execute_reply.started": "2023-12-20T19:02:38.485179Z",
          "shell.execute_reply": "2023-12-20T19:02:38.907119Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkhlS3fy7Z1-",
        "outputId": "351ba8fd-e8f9-4d56-afbd-d0e3cb678cbc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_noseq shape: (31388, 2776)\n",
            "X_val_noseq shape: (3488, 2776)\n",
            "cat_train_noseq shape: (31388,)\n",
            "cat_val_noseq shape: (3488,)\n",
            "start_times_train_noseq shape: (31388,)\n",
            "end_times_train_noseq shape: (31388,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_size=200\n",
        "stride_size=12\n",
        "\n",
        "X_train, y_train, cats = build_sequences(X_train_noseq,\n",
        "                                   window=window_size,\n",
        "                                   stride=stride_size,\n",
        "                                   start_times=start_times_train_noseq,\n",
        "                                   end_times=end_times_train_noseq,\n",
        "                                   categories=cat_train_noseq)\n",
        "\n",
        "X_val, y_val, cats_val = build_sequences(X_val_noseq,\n",
        "                                   window=window_size,\n",
        "                                   stride=stride_size,\n",
        "                                   start_times=start_times_val_noseq,\n",
        "                                   end_times=end_times_val_noseq,\n",
        "                                   categories=cat_val_noseq)\n",
        "\n",
        "print(X_train.shape, y_train.shape, cats.shape)\n",
        "print( X_val.shape, y_val.shape, cats_val.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:02:44.843544Z",
          "iopub.execute_input": "2023-12-20T19:02:44.844464Z",
          "iopub.status.idle": "2023-12-20T19:02:46.682252Z",
          "shell.execute_reply.started": "2023-12-20T19:02:44.844427Z",
          "shell.execute_reply": "2023-12-20T19:02:46.681248Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tY_w60Fh7Z1-",
        "outputId": "3793d0fb-2dee-4842-b959-b244f73b3449"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(386864, 200) (386864, 18) (386864,)\n",
            "(43273, 200) (43273, 18) (43273,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new=X_train.copy()\n",
        "jitter_factor=0.1\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "for index in range(X_train.shape[0]):\n",
        "\n",
        "  input=X_train[index].copy()\n",
        "\n",
        "  nottomask=np.where(input!=0.)[0]\n",
        "  #print(len(X_new[index, nottomask]))\n",
        "\n",
        "  if(len(nottomask)>0):\n",
        "    jitter = np.random.normal(loc=0, scale=jitter_factor*np.std(input[nottomask]), size=len(nottomask))\n",
        "\n",
        "    X_new[index, nottomask]+=jitter\n",
        "\n"
      ],
      "metadata": {
        "id": "YeRpR8304vP7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new2=X_train.copy()\n",
        "jitter_factor=0.1\n",
        "\n",
        "#CHANGING THE SEED\n",
        "np.random.seed(50)\n",
        "\n",
        "for index in range(X_train.shape[0]):\n",
        "\n",
        "  input=X_train[index].copy()\n",
        "\n",
        "  nottomask=np.where(input!=0.)[0]\n",
        "  #print(len(X_new[index, nottomask]))\n",
        "\n",
        "  if(len(nottomask)>0):\n",
        "    jitter = np.random.normal(loc=0, scale=jitter_factor*np.std(input[nottomask]), size=len(nottomask))\n",
        "\n",
        "    X_new2[index, nottomask]+=jitter"
      ],
      "metadata": {
        "id": "tvBYsJeGAj5v"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = np.vstack((X_train, X_new, X_new2))\n",
        "y_all=np.vstack((y_train, y_train, y_train))\n",
        "np.shape(X_all), np.shape(y_all)"
      ],
      "metadata": {
        "id": "A_LfesIHBqYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba2d679f-11b3-4607-d3c9-a39e1c23ba4b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1160592, 200), (1160592, 18))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class data_augmentation(tf.keras.layers.Layer):\n",
        "    def __init__(self, jitter_factor=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.jitter_factor = jitter_factor\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if training:\n",
        "            inputs = inputs.numpy()\n",
        "\n",
        "            nottomask=np.where(inputs!=0.)[0]\n",
        "\n",
        "            # Add jitter by adding random noise ONLY to the nonzero positions.\n",
        "            jitter = np.random.normal(loc=0, scale=self.jitter_factor*np.std(inputs[nottomask]), size=len(nottomask))\n",
        "            inputs[nottomask] += jitter\n",
        "\n",
        "        return inputs\n",
        "\n",
        "        input=X_noout2[index].copy()"
      ],
      "metadata": {
        "id": "8RrzTjGou2h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Time2Vec Layer\n",
        "class Time2Vec(tf.keras.layers.Layer):\n",
        "    def __init__(self, kernel_size=1):\n",
        "        super(Time2Vec, self).__init__(trainable=True, name='Time2VecLayer')\n",
        "        self.k = kernel_size\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Determine feature dimension from the last dimension of the input shape\n",
        "        feature_dim = input_shape[-1]\n",
        "        if feature_dim is None:\n",
        "            raise ValueError(\"The feature dimension of the input must be defined.\")\n",
        "\n",
        "        # Initialize weights\n",
        "        self.wb = self.add_weight(name='wb', shape=(feature_dim,), initializer='uniform', trainable=True)\n",
        "        self.bb = self.add_weight(name='bb', shape=(feature_dim,), initializer='uniform', trainable=True)\n",
        "        # Adjust the shape of wa and ba to match the kernel size\n",
        "        self.wa = self.add_weight(name='wa', shape=(feature_dim, self.k), initializer='uniform', trainable=True)\n",
        "        self.ba = self.add_weight(name='ba', shape=(self.k,), initializer='uniform', trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Linear part\n",
        "        linear = self.wb * x + self.bb\n",
        "\n",
        "        # Broadcasting to match the dimensions\n",
        "        # The shapes of wa and x are made compatible for batch matrix multiplication\n",
        "        sin_trans = tf.math.sin(tf.linalg.matmul(x, self.wa) + self.ba)\n",
        "\n",
        "        # Concatenate linear and sin_trans along the last dimension\n",
        "        return tf.concat([linear, sin_trans], axis=-1)\n",
        "\n",
        "# Modify the LSTM model to include Time2Vec\n",
        "def build_lstm_seq2seq_attention_t2v(input_shape, n_units, time2vec_dim,N_values_to_predict=18):\n",
        "\n",
        "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "    category_input = tfkl.Input(shape=(1,), name='Category_Input')  # Assuming a single numeric category\n",
        "\n",
        "    # Time2Vec integration\n",
        "    time_embedding = Time2Vec(time2vec_dim)(input_layer)\n",
        "\n",
        "    encoder_x, encoder_h, encoder_c = tfkl.LSTM(units=n_units, return_sequences=True, return_state=True)(time_embedding)\n",
        "    decoder_in = tfkl.RepeatVector(1)(encoder_h)\n",
        "    x = tfkl.LSTM(units=n_units, return_sequences=True, return_state=False)(decoder_in, initial_state=[encoder_h, encoder_c])\n",
        "    decoder_x = tfkl.Bidirectional(tfkl.LSTM(units=int(n_units/2), return_sequences=True, return_state=False))(x)\n",
        "\n",
        "    attention = tfkl.Dot(axes=[2,2])([decoder_x, encoder_x])\n",
        "    attention = tfkl.Activation('softmax')(attention)\n",
        "    context = tfkl.Dot(axes=[2,1])([attention, encoder_x])\n",
        "\n",
        "    concatenated_c = tfkl.Concatenate()([context, decoder_x])\n",
        "    concatenated_c = tfkl.Flatten()(concatenated_c)\n",
        "    output_layer = tfkl.Dense(N_values_to_predict)(concatenated_c)  # Number of telescope values\n",
        "\n",
        "    model = tf.keras.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    return model\n",
        "\n",
        "input_shape = (200,1)\n",
        "time2vec_dim = 3\n",
        "n_units = 64\n",
        "model = build_lstm_seq2seq_attention_t2v(input_shape,n_units,time2vec_dim)\n",
        "model.summary()\n",
        "model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(1e-3), metrics=['mae'])\n",
        "Model: \"model\"\n"
      ],
      "metadata": {
        "id": "TZdbZ3ir8P4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a11e0b6-28e2-4994-e01f-c445f9f7c899"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " Input (InputLayer)          [(None, 200, 1)]             0         []                            \n",
            "                                                                                                  \n",
            " Time2VecLayer (Time2Vec)    (None, 200, 4)               8         ['Input[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_9 (LSTM)               [(None, 200, 64),            17664     ['Time2VecLayer[0][0]']       \n",
            "                              (None, 64),                                                         \n",
            "                              (None, 64)]                                                         \n",
            "                                                                                                  \n",
            " repeat_vector_3 (RepeatVec  (None, 1, 64)                0         ['lstm_9[0][1]']              \n",
            " tor)                                                                                             \n",
            "                                                                                                  \n",
            " lstm_10 (LSTM)              (None, 1, 64)                33024     ['repeat_vector_3[0][0]',     \n",
            "                                                                     'lstm_9[0][1]',              \n",
            "                                                                     'lstm_9[0][2]']              \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirecti  (None, 1, 64)                24832     ['lstm_10[0][0]']             \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dot_6 (Dot)                 (None, 1, 200)               0         ['bidirectional_3[0][0]',     \n",
            "                                                                     'lstm_9[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 1, 200)               0         ['dot_6[0][0]']               \n",
            "                                                                                                  \n",
            " dot_7 (Dot)                 (None, 1, 64)                0         ['activation_3[0][0]',        \n",
            "                                                                     'lstm_9[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 1, 128)               0         ['dot_7[0][0]',               \n",
            " )                                                                   'bidirectional_3[0][0]']     \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)         (None, 128)                  0         ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 18)                   2322      ['flatten_3[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 77850 (304.10 KB)\n",
            "Trainable params: 77850 (304.10 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=50\n",
        "batch_size=256\n",
        "history = model.fit(\n",
        "    X_all,\n",
        "    y_all,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs = epochs,\n",
        "    batch_size = batch_size,\n",
        "    callbacks = [\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=3, factor=0.5, min_lr=1e-5)\n",
        "    ]\n",
        ").history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-20T19:04:49.145132Z",
          "iopub.execute_input": "2023-12-20T19:04:49.145518Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTYHZsy87Z1_",
        "outputId": "5e3387c1-229e-465a-8bb4-b68c79a11cbd"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4534/4534 [==============================] - 68s 14ms/step - loss: 0.0135 - mae: 0.0777 - val_loss: 0.0109 - val_mae: 0.0692 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0103 - mae: 0.0680 - val_loss: 0.0103 - val_mae: 0.0669 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0093 - mae: 0.0641 - val_loss: 0.0094 - val_mae: 0.0636 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0089 - mae: 0.0623 - val_loss: 0.0091 - val_mae: 0.0611 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0087 - mae: 0.0613 - val_loss: 0.0090 - val_mae: 0.0617 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0085 - mae: 0.0606 - val_loss: 0.0088 - val_mae: 0.0605 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0083 - mae: 0.0601 - val_loss: 0.0087 - val_mae: 0.0601 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0082 - mae: 0.0595 - val_loss: 0.0085 - val_mae: 0.0594 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0081 - mae: 0.0591 - val_loss: 0.0086 - val_mae: 0.0598 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "4534/4534 [==============================] - 58s 13ms/step - loss: 0.0079 - mae: 0.0587 - val_loss: 0.0085 - val_mae: 0.0597 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0079 - mae: 0.0583 - val_loss: 0.0084 - val_mae: 0.0589 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0078 - mae: 0.0581 - val_loss: 0.0083 - val_mae: 0.0586 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "4534/4534 [==============================] - 60s 13ms/step - loss: 0.0077 - mae: 0.0578 - val_loss: 0.0083 - val_mae: 0.0583 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0076 - mae: 0.0575 - val_loss: 0.0083 - val_mae: 0.0590 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0076 - mae: 0.0573 - val_loss: 0.0083 - val_mae: 0.0583 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0075 - mae: 0.0571 - val_loss: 0.0082 - val_mae: 0.0582 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0073 - mae: 0.0563 - val_loss: 0.0082 - val_mae: 0.0580 - lr: 5.0000e-04\n",
            "Epoch 18/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0072 - mae: 0.0561 - val_loss: 0.0081 - val_mae: 0.0578 - lr: 5.0000e-04\n",
            "Epoch 19/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0072 - mae: 0.0560 - val_loss: 0.0082 - val_mae: 0.0580 - lr: 5.0000e-04\n",
            "Epoch 20/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0072 - mae: 0.0559 - val_loss: 0.0082 - val_mae: 0.0579 - lr: 5.0000e-04\n",
            "Epoch 21/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0071 - mae: 0.0554 - val_loss: 0.0081 - val_mae: 0.0579 - lr: 2.5000e-04\n",
            "Epoch 22/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0070 - mae: 0.0553 - val_loss: 0.0082 - val_mae: 0.0578 - lr: 2.5000e-04\n",
            "Epoch 23/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0070 - mae: 0.0553 - val_loss: 0.0081 - val_mae: 0.0576 - lr: 2.5000e-04\n",
            "Epoch 24/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0070 - mae: 0.0550 - val_loss: 0.0081 - val_mae: 0.0577 - lr: 1.2500e-04\n",
            "Epoch 25/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0070 - mae: 0.0550 - val_loss: 0.0081 - val_mae: 0.0576 - lr: 1.2500e-04\n",
            "Epoch 26/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0550 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.2500e-04\n",
            "Epoch 27/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0548 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 6.2500e-05\n",
            "Epoch 28/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0548 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 6.2500e-05\n",
            "Epoch 29/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0548 - val_loss: 0.0081 - val_mae: 0.0576 - lr: 6.2500e-05\n",
            "Epoch 30/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 3.1250e-05\n",
            "Epoch 31/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0574 - lr: 3.1250e-05\n",
            "Epoch 32/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0576 - lr: 3.1250e-05\n",
            "Epoch 33/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.5625e-05\n",
            "Epoch 34/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.5625e-05\n",
            "Epoch 35/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.5625e-05\n",
            "Epoch 36/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0547 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.0000e-05\n",
            "Epoch 37/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0546 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.0000e-05\n",
            "Epoch 38/50\n",
            "4534/4534 [==============================] - 59s 13ms/step - loss: 0.0069 - mae: 0.0546 - val_loss: 0.0081 - val_mae: 0.0575 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "model.save('time2vecAUMG_LAST_200_12_lstm_attention_sequenzelunghe_no72')\n",
        "shutil.make_archive('time2vecAUMG_LAST_200_12_lstm_attention_sequenzelunghe_no72', 'zip', 'time2vecAUMG_LAST_200_12_lstm_attention_sequenzelunghe_no72')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pAdQeE0yABpZ",
        "outputId": "3fdf71cf-2146-45b5-fbd8-9b0e87fdfc01"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/time2vecAUMG_LAST_200_12_lstm_attention_sequenzelunghe_no72.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6w5p0H6NXJY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}